{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f084e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"melb_data.csv\")\n",
    "y = data.Price\n",
    "\n",
    "melb_predictors = data.drop([\"Price\"], axis=1)\n",
    "X = melb_predictors.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdfc27d",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc20cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed18588",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416130ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Car', 'BuildingArea', 'YearBuilt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6371c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_test = X_test.drop(cols_with_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebb33d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop columns with missing values):\n",
      "188319.41510449542\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36d751e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Imputation):\n",
      "181357.59052352898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n",
    "\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_test.columns = X_test.columns\n",
    "\n",
    "print(\"MAE from Approach 2 (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ea029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (An Extension to Imputation):\n",
      "182519.64198926993\n"
     ]
    }
   ],
   "source": [
    "X_train_plus = X_train.copy()\n",
    "X_test_plus = X_test.copy()\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + \"_was_missing\"] = X_train_plus[col].isnull()\n",
    "    X_test_plus[col + \"_was_missing\"] = X_test_plus[col].isnull()\n",
    "    \n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_test_plus = pd.DataFrame(my_imputer.transform(X_test_plus))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_test_plus.columns = X_test_plus.columns\n",
    "\n",
    "print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a3f48",
   "metadata": {},
   "source": [
    "# Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9de3ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('melb_data.csv')\n",
    "\n",
    "# Separate target from predictors\n",
    "y = data.Price\n",
    "X = data.drop(['Price'], axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# Drop columns with missing values (simplest approach)\n",
    "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
    "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1692ab5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n",
       "12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n",
       "6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n",
       "8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n",
       "2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n",
       "6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n",
       "\n",
       "       Bathroom  Landsize  Lattitude  Longtitude  Propertycount  \n",
       "12167       1.0       0.0  -37.85984    144.9867        13240.0  \n",
       "6524        2.0     193.0  -37.85800    144.9005         6380.0  \n",
       "8413        1.0     555.0  -37.79880    144.8220         3755.0  \n",
       "2919        1.0     265.0  -37.70830    144.9158         8870.0  \n",
       "6043        1.0     673.0  -37.76230    144.8272         4217.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "681b0ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81a4af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52f47e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "175703.48185157913\n"
     ]
    }
   ],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "603a7af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "165936.40548390493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "# Apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
    "\n",
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6b2d021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "166089.4893009678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95320d12",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "135a7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('melb_data.csv')\n",
    "\n",
    "# Separate target from predictors\n",
    "y = data.Price\n",
    "X = data.drop(['Price'], axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e26fba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numerical_transformer = SimpleImputer(strategy=\"constant\")\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad25ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33a2ac8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  SimpleImputer(strategy='constant'),\n",
       "                                                  ['Rooms', 'Distance',\n",
       "                                                   'Postcode', 'Bedroom2',\n",
       "                                                   'Bathroom', 'Car',\n",
       "                                                   'Landsize', 'BuildingArea',\n",
       "                                                   'YearBuilt', 'Lattitude',\n",
       "                                                   'Longtitude',\n",
       "                                                   'Propertycount']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Type', 'Method',\n",
       "                                                   'Regionname'])])),\n",
       "                ('model', RandomForestRegressor(random_state=0))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa066ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d511731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 160679.18917034855\n"
     ]
    }
   ],
   "source": [
    "score = mean_absolute_error(y_valid, preds)\n",
    "print(\"MAE:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9772440b",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "816d124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('melb_data.csv')\n",
    "\n",
    "# Select subset of predictors\n",
    "cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\n",
    "X = data[cols_to_use]\n",
    "\n",
    "# Select target\n",
    "y = data.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "072ccf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessing\", SimpleImputer()),\n",
    "    (\"model\", RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0bcf5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE scores\n",
      "[301628.7893587  303164.4782723  287298.331666   236061.84754543\n",
      " 260383.45111427]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = -1 * cross_val_score(pipeline, X, y, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "print(\"MAE scores\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a6bab01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277707.3795913405"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b1b23",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "477a3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('melb_data.csv')\n",
    "\n",
    "# Select subset of predictors\n",
    "cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\n",
    "X = data[cols_to_use]\n",
    "\n",
    "# Select target\n",
    "y = data.Price\n",
    "\n",
    "# Separate data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f7f55ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8bf1df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 234077.8435382916\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_valid)\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ab10c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1189143.25000\n",
      "[1]\tvalidation_0-rmse:1138787.87500\n",
      "[2]\tvalidation_0-rmse:1091061.75000\n",
      "[3]\tvalidation_0-rmse:1046287.06250\n",
      "[4]\tvalidation_0-rmse:1004104.37500\n",
      "[5]\tvalidation_0-rmse:963983.43750\n",
      "[6]\tvalidation_0-rmse:926153.50000\n",
      "[7]\tvalidation_0-rmse:890487.25000\n",
      "[8]\tvalidation_0-rmse:856916.00000\n",
      "[9]\tvalidation_0-rmse:825769.75000\n",
      "[10]\tvalidation_0-rmse:796123.56250\n",
      "[11]\tvalidation_0-rmse:768222.25000\n",
      "[12]\tvalidation_0-rmse:742347.81250\n",
      "[13]\tvalidation_0-rmse:717410.12500\n",
      "[14]\tvalidation_0-rmse:694435.18750\n",
      "[15]\tvalidation_0-rmse:672891.50000\n",
      "[16]\tvalidation_0-rmse:652564.56250\n",
      "[17]\tvalidation_0-rmse:633691.43750\n",
      "[18]\tvalidation_0-rmse:616194.75000\n",
      "[19]\tvalidation_0-rmse:599957.62500\n",
      "[20]\tvalidation_0-rmse:585015.31250\n",
      "[21]\tvalidation_0-rmse:571279.37500\n",
      "[22]\tvalidation_0-rmse:558039.62500\n",
      "[23]\tvalidation_0-rmse:545932.00000\n",
      "[24]\tvalidation_0-rmse:534508.12500\n",
      "[25]\tvalidation_0-rmse:524402.81250\n",
      "[26]\tvalidation_0-rmse:514463.21875\n",
      "[27]\tvalidation_0-rmse:505481.62500\n",
      "[28]\tvalidation_0-rmse:497531.65625\n",
      "[29]\tvalidation_0-rmse:489775.84375\n",
      "[30]\tvalidation_0-rmse:482443.71875\n",
      "[31]\tvalidation_0-rmse:475661.71875\n",
      "[32]\tvalidation_0-rmse:469179.62500\n",
      "[33]\tvalidation_0-rmse:463213.43750\n",
      "[34]\tvalidation_0-rmse:457606.06250\n",
      "[35]\tvalidation_0-rmse:452587.68750\n",
      "[36]\tvalidation_0-rmse:448173.65625\n",
      "[37]\tvalidation_0-rmse:443821.96875\n",
      "[38]\tvalidation_0-rmse:439634.00000\n",
      "[39]\tvalidation_0-rmse:435997.21875\n",
      "[40]\tvalidation_0-rmse:432534.62500\n",
      "[41]\tvalidation_0-rmse:429229.71875\n",
      "[42]\tvalidation_0-rmse:426203.62500\n",
      "[43]\tvalidation_0-rmse:423433.53125\n",
      "[44]\tvalidation_0-rmse:420798.15625\n",
      "[45]\tvalidation_0-rmse:418184.68750\n",
      "[46]\tvalidation_0-rmse:415975.96875\n",
      "[47]\tvalidation_0-rmse:413880.62500\n",
      "[48]\tvalidation_0-rmse:411957.68750\n",
      "[49]\tvalidation_0-rmse:410286.37500\n",
      "[50]\tvalidation_0-rmse:408518.15625\n",
      "[51]\tvalidation_0-rmse:406571.53125\n",
      "[52]\tvalidation_0-rmse:404899.09375\n",
      "[53]\tvalidation_0-rmse:403564.62500\n",
      "[54]\tvalidation_0-rmse:401942.53125\n",
      "[55]\tvalidation_0-rmse:400867.37500\n",
      "[56]\tvalidation_0-rmse:399249.68750\n",
      "[57]\tvalidation_0-rmse:398166.40625\n",
      "[58]\tvalidation_0-rmse:397128.31250\n",
      "[59]\tvalidation_0-rmse:396048.71875\n",
      "[60]\tvalidation_0-rmse:395750.65625\n",
      "[61]\tvalidation_0-rmse:394888.03125\n",
      "[62]\tvalidation_0-rmse:394028.50000\n",
      "[63]\tvalidation_0-rmse:392899.46875\n",
      "[64]\tvalidation_0-rmse:392525.84375\n",
      "[65]\tvalidation_0-rmse:391926.21875\n",
      "[66]\tvalidation_0-rmse:390964.87500\n",
      "[67]\tvalidation_0-rmse:390754.28125\n",
      "[68]\tvalidation_0-rmse:390073.40625\n",
      "[69]\tvalidation_0-rmse:389331.46875\n",
      "[70]\tvalidation_0-rmse:388602.62500\n",
      "[71]\tvalidation_0-rmse:388538.68750\n",
      "[72]\tvalidation_0-rmse:388054.56250\n",
      "[73]\tvalidation_0-rmse:388125.15625\n",
      "[74]\tvalidation_0-rmse:387578.75000\n",
      "[75]\tvalidation_0-rmse:387036.81250\n",
      "[76]\tvalidation_0-rmse:386338.84375\n",
      "[77]\tvalidation_0-rmse:385851.00000\n",
      "[78]\tvalidation_0-rmse:385483.65625\n",
      "[79]\tvalidation_0-rmse:384873.34375\n",
      "[80]\tvalidation_0-rmse:384464.34375\n",
      "[81]\tvalidation_0-rmse:384129.18750\n",
      "[82]\tvalidation_0-rmse:383604.56250\n",
      "[83]\tvalidation_0-rmse:383326.65625\n",
      "[84]\tvalidation_0-rmse:383014.56250\n",
      "[85]\tvalidation_0-rmse:382564.12500\n",
      "[86]\tvalidation_0-rmse:382082.43750\n",
      "[87]\tvalidation_0-rmse:381828.56250\n",
      "[88]\tvalidation_0-rmse:381683.15625\n",
      "[89]\tvalidation_0-rmse:381912.34375\n",
      "[90]\tvalidation_0-rmse:381825.34375\n",
      "[91]\tvalidation_0-rmse:381497.56250\n",
      "[92]\tvalidation_0-rmse:381105.09375\n",
      "[93]\tvalidation_0-rmse:381055.15625\n",
      "[94]\tvalidation_0-rmse:380826.21875\n",
      "[95]\tvalidation_0-rmse:380780.37500\n",
      "[96]\tvalidation_0-rmse:380589.37500\n",
      "[97]\tvalidation_0-rmse:380421.00000\n",
      "[98]\tvalidation_0-rmse:379900.78125\n",
      "[99]\tvalidation_0-rmse:379575.28125\n",
      "[100]\tvalidation_0-rmse:379571.40625\n",
      "[101]\tvalidation_0-rmse:379519.68750\n",
      "[102]\tvalidation_0-rmse:379393.53125\n",
      "[103]\tvalidation_0-rmse:379238.28125\n",
      "[104]\tvalidation_0-rmse:379386.37500\n",
      "[105]\tvalidation_0-rmse:379417.93750\n",
      "[106]\tvalidation_0-rmse:379380.81250\n",
      "[107]\tvalidation_0-rmse:379421.25000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
       "             max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=500, n_jobs=4,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=500, learning_rate=0.05)\n",
    "model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9ca21",
   "metadata": {},
   "source": [
    "# Data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "997518e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No important code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
